{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12215b5f-0d6f-4b20-b41e-8b876af6f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "KL-GAN with Multiple Adversarial Objectives\n",
    "--------------------------------------------\n",
    "This script showcases training KL-GAN on CelebA with options for:\n",
    "    KL-GAN, LS-GAN, WGAN-GP, Hinge-GAN, R1-GAN.\n",
    "\n",
    "We run 5 different seeds for each method.\n",
    "\"\"\"\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import random\n",
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import albumentations as A\n",
    "import albumentations.pytorch as AP\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.progress.rich_progress import RichProgressBar, RichProgressBarTheme\n",
    "from torchvision import transforms, models\n",
    "from torch.distributions import Normal, kl_divergence, Independent\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 1. Feature extraction functions for FID-like calculations\n",
    "# -----------------------\n",
    "inception_model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
    "inception_model.cuda().eval()\n",
    "inception_model.fc = nn.Identity()\n",
    "for param in inception_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def get_features(real_image, fake_image, eps=1e-3):\n",
    "    \"\"\"\n",
    "    Extracts features from real and fake images using Inception v3 and returns\n",
    "    their mean and covariance.\n",
    "    \"\"\"\n",
    "    real_features = inception_model(real_image)\n",
    "    fake_features = inception_model(fake_image)\n",
    "    mu_real, cov_real = real_features.mean(0), torch.cov(real_features.permute(1,0))\n",
    "    mu_fake, cov_fake = fake_features.mean(0), torch.cov(fake_features.permute(1,0))\n",
    "\n",
    "    cov_real += eps * torch.eye(cov_real.size(0)).to(cov_real.device)\n",
    "    cov_fake += eps * torch.eye(cov_fake.size(0)).to(cov_fake.device)\n",
    "\n",
    "    return mu_real.float(), cov_real.float(), mu_fake.float(), cov_fake.float()\n",
    "\n",
    "\n",
    "RegNet_model = models.regnet_x_3_2gf(weights=\"RegNet_X_3_2GF_Weights.DEFAULT\")\n",
    "RegNet_model.cuda().eval()\n",
    "RegNet_model.fc = nn.Identity()\n",
    "for param in RegNet_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def get_features_RegNet(real_image, fake_image, eps=1e-3):\n",
    "    \"\"\"\n",
    "    Extracts features from real and fake images using RegNet_x_3_2gf and returns\n",
    "    their mean and covariance.\n",
    "    \"\"\"\n",
    "    real_features = RegNet_model(real_image)\n",
    "    fake_features = RegNet_model(fake_image)\n",
    "\n",
    "    mu_real, cov_real = real_features.mean(0), torch.cov(real_features.permute(1,0))\n",
    "    mu_fake, cov_fake = fake_features.mean(0), torch.cov(fake_features.permute(1,0))\n",
    "\n",
    "    cov_real += eps * torch.eye(cov_real.size(0)).to(cov_real.device)\n",
    "    cov_fake += eps * torch.eye(cov_fake.size(0)).to(cov_fake.device)\n",
    "\n",
    "    return mu_real.float(), cov_real.float(), mu_fake.float(), cov_fake.float()\n",
    "\n",
    "\n",
    "def calculate_kl_divergence(mu_real, cov_real, mu_fake, cov_fake):\n",
    "    \"\"\"\n",
    "    Symmetric KL divergence between two multivariate Gaussians.\n",
    "    \"\"\"\n",
    "    true_dist = torch.distributions.MultivariateNormal(mu_real.to(torch.float32), cov_real.to(torch.float32))\n",
    "    fake_dist = torch.distributions.MultivariateNormal(mu_fake.to(torch.float32), cov_fake.to(torch.float32))\n",
    "    return 0.5 * (\n",
    "        torch.distributions.kl_divergence(fake_dist, true_dist)\n",
    "        + torch.distributions.kl_divergence(true_dist, fake_dist)\n",
    "    )\n",
    "\n",
    "def calculate_fid(mu_real, cov_real, mu_fake, cov_fake):\n",
    "    \"\"\"\n",
    "    Calculate the FID score between two distributions parameterized by\n",
    "    (mu_real, cov_real) and (mu_fake, cov_fake).\n",
    "    \"\"\"\n",
    "    mu_real = mu_real.to(torch.float64)\n",
    "    cov_real = cov_real.to(torch.float64)\n",
    "    mu_fake = mu_fake.to(torch.float64)\n",
    "    cov_fake = cov_fake.to(torch.float64)\n",
    "    \n",
    "    # (mu1 - mu2)^2\n",
    "    a = (mu_real - mu_fake).square().sum(dim=-1)\n",
    "    \n",
    "    # trace(cov1 + cov2 - 2*sqrt(cov1 cov2))\n",
    "    b = cov_real.trace() + cov_fake.trace()\n",
    "    product = cov_real @ cov_fake\n",
    "    c = 2 * torch.real(torch.linalg.eigvals(product).sqrt().sum())\n",
    "\n",
    "    return float(a + b - c)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2. Data loading: CelebA\n",
    "# -----------------------\n",
    "class CelebADataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch dataset wrapper for preloaded GPU tensors of images.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_tensor):\n",
    "        self.data = data_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    DataModule for CelebA dataset. Adjusts transforms and splits into train/val.\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, val_batch_size, data_dir=\"./img_align_celeba/img_align_celeba\"):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.val_batch_size = val_batch_size\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        self.train_transform = A.Compose([\n",
    "            A.Resize(32, 32),\n",
    "            A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "            AP.ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "        self.val_transform = A.Compose([\n",
    "            A.Resize(32, 32),\n",
    "            A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "            AP.ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        image_files = os.listdir(self.data_dir)\n",
    "        images = []\n",
    "\n",
    "        for img_file in image_files:\n",
    "            image_path = os.path.join(self.data_dir, img_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = self.train_transform(image=image)[\"image\"]\n",
    "            images.append(image)\n",
    "\n",
    "        data_tensor = torch.stack(images)\n",
    "        data_tensor = data_tensor.to(device=torch.device('cuda'), dtype=torch.bfloat16)\n",
    "\n",
    "        self.dataset = CelebADataset(data_tensor)\n",
    "        split = int(0.9 * len(self.dataset))\n",
    "        self.dataset_train, self.dataset_val = torch.utils.data.random_split(\n",
    "            self.dataset, [split, len(self.dataset) - split]\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset_train, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=0,\n",
    "            pin_memory=False\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset_val, \n",
    "            batch_size=self.val_batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=0,\n",
    "            pin_memory=False\n",
    "        )\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 3. (Optional) Latent code for storing precomputed latents\n",
    "# -----------------------\n",
    "@staticmethod\n",
    "def scale_latents_to_minus_one_one(x):\n",
    "    \"\"\"Scale raw latents -> [-1, 1].\"\"\"\n",
    "    x_scaled = x.div(2 * 3).add(0.5).clamp(0, 1)  # to [0, 1]\n",
    "    return x_scaled.mul(2).sub(1)  # to [-1, 1]\n",
    "\n",
    "@staticmethod\n",
    "def unscale_latents_from_minus_one_one(x):\n",
    "    \"\"\"Scale [-1, 1] latents -> raw latents.\"\"\"\n",
    "    x_zero_one = x.add(1).div(2)      # to [0, 1]\n",
    "    return x_zero_one.sub(0.5).mul(2 * 3)\n",
    "\n",
    "class LatentDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Stores latent codes from *.pt files in a specified directory.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dir):\n",
    "        self.latent_dir = latent_dir\n",
    "        self.latent_files = [f for f in os.listdir(latent_dir) if f.endswith('.pt')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.latent_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        latent_path = os.path.join(self.latent_dir, self.latent_files[idx])\n",
    "        latent = torch.load(latent_path)\n",
    "        return latent\n",
    "\n",
    "class LatentDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\n",
    "    DataModule for loading latent *.pt files.\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, val_batch_size, latent_dir):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.val_batch_size = val_batch_size\n",
    "        self.latent_dir = latent_dir\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset_train = LatentDataset(latent_dir=self.latent_dir)\n",
    "        self.dataset_val = LatentDataset(latent_dir=self.latent_dir)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset_val, batch_size=self.val_batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 4. Helper functions for KL-based training\n",
    "# -----------------------\n",
    "def compute_mean_std(features, epsilon=1e-10):\n",
    "    mu = features.mean(dim=0)\n",
    "    var = features.var(dim=0, unbiased=False) + epsilon\n",
    "    return mu, var\n",
    "\n",
    "def symmetric_kl_divergence(real_features, fake_features):\n",
    "    \"\"\"\n",
    "    Computes symmetric KL divergence between real and fake features.\n",
    "    \"\"\"\n",
    "    mu_real, std_real = compute_mean_std(real_features)\n",
    "    mu_fake, std_fake = compute_mean_std(fake_features)\n",
    "    real_dist = Independent(Normal(mu_real, std_real), 1)\n",
    "    fake_dist = Independent(Normal(mu_fake, std_fake), 1)\n",
    "\n",
    "    kl_real_fake = kl_divergence(real_dist, fake_dist)\n",
    "    kl_fake_real = kl_divergence(fake_dist, real_dist)\n",
    "    return 0.5 * (torch.log1p(kl_real_fake) + torch.log1p(kl_fake_real))\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 5. MinibatchDiscrimination module\n",
    "# -----------------------\n",
    "class MinibatchDiscrimination(nn.Module):\n",
    "    \"\"\"\n",
    "    A layer to help reduce mode collapse by comparing samples in a batch\n",
    "    against each other.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, kernel_dims, mean=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.kernel_dims = kernel_dims\n",
    "        self.mean = mean\n",
    "        self.T = nn.Parameter(torch.Tensor(in_features, out_features, kernel_dims))\n",
    "        nn.init.normal_(self.T, 0, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: NxA\n",
    "        # T shape: AxBxC\n",
    "        matrices = x.mm(self.T.view(self.in_features, -1))\n",
    "        matrices = matrices.view(-1, self.out_features, self.kernel_dims)\n",
    "        M = matrices.unsqueeze(0)   # 1xNxBxC\n",
    "        M_T = M.permute(1, 0, 2, 3) # Nx1xBxC\n",
    "\n",
    "        norm = torch.abs(M - M_T).sum(3)   # NxNxB\n",
    "        expnorm = torch.exp(-norm)\n",
    "        o_b = (expnorm.sum(0) - 1)         # NxB\n",
    "        if self.mean:\n",
    "            o_b /= x.size(0) - 1\n",
    "        x = torch.cat([x, o_b], 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 6. Generator and Discriminator with DIM as a hyperparameter\n",
    "# -----------------------\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    KL-GAN Generator with trainable distribution parameters (mu, log_sigma).\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim=128, dim=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dim = dim\n",
    "\n",
    "        # Trainable distribution parameters\n",
    "        self.mu = nn.Parameter(torch.zeros(latent_dim))\n",
    "        self.log_sigma = nn.Parameter(torch.zeros(latent_dim))\n",
    "\n",
    "        # Main architecture\n",
    "        self.preprocess = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 4 * 4 * dim),\n",
    "            nn.Mish(),\n",
    "            nn.LayerNorm(4 * 4 * dim)\n",
    "        )\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(4 * dim, 2 * dim, 3, 1, 1),\n",
    "            nn.Mish(),\n",
    "            nn.ConvTranspose2d(2 * dim, 2 * dim, 5),\n",
    "            nn.Mish(),\n",
    "            nn.InstanceNorm2d(2 * dim, affine=True),\n",
    "            nn.Conv2d(2 * dim, 2 * dim, 3, 1, 1),\n",
    "            nn.Mish()\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2 * dim, 2 * dim, 4, 2, 1),\n",
    "            nn.Mish(),\n",
    "            nn.InstanceNorm2d(2 * dim, affine=True),\n",
    "            nn.Conv2d(2 * dim, 2 * dim, 3, 1, 1),\n",
    "            nn.Mish()\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2 * dim, dim, 4, 2, 1),\n",
    "            nn.Mish(),\n",
    "            nn.InstanceNorm2d(dim, affine=True),\n",
    "            nn.Conv2d(dim, dim, 3, 1, 1),\n",
    "            nn.Mish()\n",
    "        )\n",
    "        self.deconv_out = nn.Conv2d(dim, 3, 3, 1, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, eps):\n",
    "        sigma = torch.exp(self.log_sigma)\n",
    "        z = self.mu + sigma * eps\n",
    "        \n",
    "        out = self.preprocess(z)\n",
    "        out = out.view(-1, 4 * self.dim, 2, 2)\n",
    "        out = self.block1(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        out = self.deconv_out(out)\n",
    "        out = self.tanh(out)\n",
    "        return out\n",
    "\n",
    "from torch.nn.utils import spectral_norm as SpectralNorm\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, type_model, minibatch_shader=False, dim=128, use_minibatch=True):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.type_model = type_model\n",
    "        self.minibatch_shader = minibatch_shader\n",
    "        self.dim = dim\n",
    "        self.use_minibatch = use_minibatch\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, dim, 5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            \n",
    "            nn.Conv2d(dim, 2 * dim, 5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            \n",
    "            nn.Conv2d(2 * dim, 4 * dim, 5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            \n",
    "            nn.Conv2d(4 * dim, 8 * dim, 2, stride=2),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            \n",
    "            nn.Conv2d(8 * dim, 16 * dim, 2, stride=2),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Linear(16 * dim, 8)\n",
    "        if use_minibatch:\n",
    "            self.minibatch = MinibatchDiscrimination(8, 8, 1)\n",
    "            self.final = nn.Linear(16, 1)\n",
    "        else:\n",
    "            self.final = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.type_model == \"KL-GAN\":\n",
    "            return self.forward_kl(x)\n",
    "        else:\n",
    "            return self.forward_average(x)\n",
    "\n",
    "    def forward_average(self, x):\n",
    "        out = self.main(x)\n",
    "        out = out.flatten(1)\n",
    "        out = self.output(out)\n",
    "        if self.use_minibatch:\n",
    "            out = self.minibatch(out)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    "\n",
    "    def forward_kl(self, x):\n",
    "        \"\"\"\n",
    "        For KL-GAN, we chunk real/fake images from x along the batch dimension.\n",
    "        \"\"\"\n",
    "        out = self.main(x)\n",
    "        out = out.flatten(1)\n",
    "        out = self.output(out)\n",
    "        \n",
    "        if self.use_minibatch:\n",
    "            if self.minibatch_shader:\n",
    "                real_features, fake_features = self.minibatch(out).chunk(2, dim=0)\n",
    "                return symmetric_kl_divergence(real_features, fake_features)\n",
    "            else:\n",
    "                real_features, fake_features = out.chunk(2, dim=0)\n",
    "                return symmetric_kl_divergence(\n",
    "                    self.minibatch(real_features),\n",
    "                    self.minibatch(fake_features)\n",
    "                )\n",
    "        else:\n",
    "            real_features, fake_features = out.chunk(2, dim=0)\n",
    "            return symmetric_kl_divergence(real_features, fake_features)\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 8. Multi-scale generator and discriminator\n",
    "# -----------------------\n",
    "class StableFlowGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-scale generator with \"to_rgb\" at each level.\n",
    "    Generation starts at 4x4, then 8x8, 16x16, etc. up to the specified resolution.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim=128,\n",
    "        resolution=32,\n",
    "        dim=128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.resolution = resolution\n",
    "        \n",
    "        # Calculate number of levels needed (e.g., if resolution=32, levels will be 4->8->16->32)\n",
    "        self.num_levels = int(math.log2(self.resolution)) - 2  # for 32 -> (log2(32)=5) -> 5 - 2 = 3 levels\n",
    "\n",
    "        # Distribution parameters (as in KL-GAN Generator)\n",
    "        self.mu = nn.Parameter(torch.zeros(latent_dim))\n",
    "        self.log_sigma = nn.Parameter(torch.zeros(latent_dim))\n",
    "\n",
    "        # Initial block to project latent to 4x4 spatial tensor\n",
    "        initial_channels = dim * 4\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 4 * 4 * initial_channels),\n",
    "            nn.Mish()\n",
    "        )\n",
    "        self.initial_norm = nn.LayerNorm([initial_channels, 4, 4])\n",
    "\n",
    "        # Create blocks for growing resolution\n",
    "        self.blocks = nn.ModuleList()\n",
    "        self.to_rgb = nn.ModuleList()\n",
    "        \n",
    "        in_channels = initial_channels\n",
    "        for level in range(self.num_levels):\n",
    "            out_channels = max(dim, in_channels // 2)\n",
    "            block = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "                nn.Mish(),\n",
    "                nn.InstanceNorm2d(out_channels, affine=True),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "                nn.Mish(),\n",
    "                nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            )\n",
    "            self.blocks.append(block)\n",
    "            self.to_rgb.append(\n",
    "                nn.Conv2d(out_channels, 3, kernel_size=1)  # to_rgb for each level\n",
    "            )\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, eps):\n",
    "        sigma = torch.exp(self.log_sigma)\n",
    "        z = self.mu + sigma * eps  # sample from parameterized distribution\n",
    "\n",
    "        # Initial 4x4 tensor\n",
    "        out = self.initial(z)\n",
    "        N = out.size(0)\n",
    "        # Transform to (N, in_channels, 4, 4)\n",
    "        initial_channels = self.blocks[0][1].in_channels if len(self.blocks) > 0 else self.initial_norm.normalized_shape[0]\n",
    "        out = out.view(N, initial_channels, 4, 4)\n",
    "        out = self.initial_norm(out)\n",
    "\n",
    "        images = []\n",
    "        current = out\n",
    "        for block, to_rgb in zip(self.blocks, self.to_rgb):\n",
    "            current = block(current)\n",
    "            rgb = to_rgb(current)\n",
    "            rgb = self.tanh(rgb)\n",
    "            images.append(rgb)\n",
    "\n",
    "        # Return the *entire* list: [4x4, 8x8, 16x16, ..., resolution]\n",
    "        return images\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Multi-scale discriminator\n",
    "# -----------------------\n",
    "class StableFlowDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-scale discriminator that takes a list of images\n",
    "    of different sizes [4x4, 8x8, ..., resolution x resolution].\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        resolution=32,\n",
    "        dim=128,\n",
    "        type_model=\"KL-GAN\",\n",
    "        minibatch_shader=False,\n",
    "        use_minibatch=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.resolution = resolution\n",
    "        self.type_model = type_model\n",
    "        self.minibatch_shader = minibatch_shader\n",
    "        self.use_minibatch = use_minibatch\n",
    "\n",
    "        self.num_levels = int(math.log2(self.resolution)) - 2\n",
    "\n",
    "        # from_rgb blocks + discriminator blocks\n",
    "        self.from_rgb = nn.ModuleList()\n",
    "        self.blocks = nn.ModuleList()\n",
    "\n",
    "        # Based on the generator, at the beginning (4x4) we had dim*4 channels\n",
    "        in_channels = dim * 4\n",
    "        prev_channels = 0  # for tracking channels from previous level\n",
    "\n",
    "        for level in range(self.num_levels):\n",
    "            out_channels = max(dim, in_channels // 2)\n",
    "\n",
    "            # from_rgb remains unchanged\n",
    "            frgb = nn.Conv2d(3, out_channels, kernel_size=1)\n",
    "            self.from_rgb.append(frgb)\n",
    "\n",
    "            # Discriminator block now takes out_channels + prev_channels\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(out_channels + prev_channels, out_channels, 3, padding=1),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.AvgPool2d(2)\n",
    "            )\n",
    "            self.blocks.append(block)\n",
    "\n",
    "            prev_channels = out_channels  # save for next level\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.fc = nn.Linear(in_channels * 4 * 4, 8)  # equivalent to output\n",
    "        if self.use_minibatch:\n",
    "            self.minibatch = MinibatchDiscrimination(8, 8, 1)\n",
    "            self.final = nn.Linear(16, 1)\n",
    "        else:\n",
    "            self.final = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, multi_res_images):\n",
    "        \"\"\"\n",
    "        multi_res_images is a list of [4x4, 8x8, ..., resolution].\n",
    "        But the order is usually from smaller to larger.\n",
    "        In the code below we want to go from larger resolution to smaller -\n",
    "        so we reverse the list.\n",
    "        \n",
    "        If KL-GAN, then in each tensor batch = 2N (concatenated real/fake).\n",
    "        \"\"\"\n",
    "        if self.type_model == \"KL-GAN\":\n",
    "            return self.forward_kl(multi_res_images)\n",
    "        else:\n",
    "            return self.forward_average(multi_res_images)\n",
    "\n",
    "    def forward_average(self, x):\n",
    "        features = self.forward_multiscale(x)  \n",
    "        if self.use_minibatch:\n",
    "            features = self.minibatch(features)\n",
    "        out = self.final(features)\n",
    "        return out\n",
    "\n",
    "    def forward_kl(self, x):\n",
    "        \"\"\"\n",
    "        x[i] is [2N, 3, H, W].\n",
    "        After forward_multiscale we get [2N, 8] (after fc).\n",
    "        Then chunk into real/fake and compute symmetric_kl_divergence.\n",
    "        \"\"\"\n",
    "        features = self.forward_multiscale(x)\n",
    "        if self.use_minibatch:\n",
    "            if self.minibatch_shader:\n",
    "                real_f, fake_f = self.minibatch(features).chunk(2, dim=0)\n",
    "                return symmetric_kl_divergence(real_f, fake_f)\n",
    "            else:\n",
    "                real_chunk, fake_chunk = features.chunk(2, dim=0)\n",
    "                return symmetric_kl_divergence(\n",
    "                    self.minibatch(real_chunk),\n",
    "                    self.minibatch(fake_chunk)\n",
    "                )\n",
    "        else:\n",
    "            real_chunk, fake_chunk = features.chunk(2, dim=0)\n",
    "            return symmetric_kl_divergence(real_chunk, fake_chunk)\n",
    "\n",
    "    def forward_multiscale(self, multi_res_images):\n",
    "        # Reverse the list to go from larger resolution to smaller\n",
    "        multi_res_images = multi_res_images[::-1]\n",
    "\n",
    "        x = None\n",
    "        for img, frgb, block in zip(multi_res_images, self.from_rgb, self.blocks):\n",
    "            # from_rgb\n",
    "            feat = frgb(img)\n",
    "            if x is None:\n",
    "                x = feat\n",
    "            else:\n",
    "                # concatenate features\n",
    "                x = torch.cat([x, feat], dim=1)\n",
    "            # convolutional block + avgpool\n",
    "            x = block(x)\n",
    "        x = self.final_conv(x)  # more convolutions at 4x4\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)          # -> [batch, 8]\n",
    "        return x                # next minibatch + final\n",
    "        \n",
    "# -----------------------\n",
    "# 7. PyTorch Lightning Module for training\n",
    "# -----------------------\n",
    "class GAN_Training(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    LightningModule for training KL-GAN (and other variants).\n",
    "    Added hyperparameter use_multiscale to enable multi-scale mode.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float = 0.00002,\n",
    "        batch_size: int = 256,\n",
    "        seed_value: int = 1,\n",
    "        type_model: str = \"KL-GAN\",\n",
    "        latent_dim: int = 128,\n",
    "        dim: int = 128,\n",
    "        use_minibatch: bool = True,\n",
    "        # New hyperparameter\n",
    "        use_multiscale: bool = False,\n",
    "        resolution: int = 32,   # to pass to multi-scale G/D\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.automatic_optimization = False\n",
    "        \n",
    "        if seed_value is not None:\n",
    "            pl.seed_everything(seed_value)\n",
    "            torch.manual_seed(seed_value)\n",
    "            torch.cuda.manual_seed(seed_value)\n",
    "            random.seed(seed_value)\n",
    "\n",
    "        # If multi-scale mode is enabled\n",
    "        if self.hparams.use_multiscale:\n",
    "            # Multi-scale G/D\n",
    "            self.generator = StableFlowGenerator(\n",
    "                latent_dim=latent_dim, \n",
    "                resolution=resolution,\n",
    "                dim=dim\n",
    "            )\n",
    "            self.discriminator = StableFlowDiscriminator(\n",
    "                resolution=resolution,\n",
    "                dim=dim,\n",
    "                type_model=type_model,\n",
    "                use_minibatch=use_minibatch\n",
    "            )\n",
    "        else:\n",
    "            # Standard implementations\n",
    "            self.generator = Generator(latent_dim=latent_dim, dim=dim)\n",
    "            self.discriminator = Discriminator(\n",
    "                type_model=type_model, \n",
    "                dim=dim,\n",
    "                use_minibatch=use_minibatch\n",
    "            )\n",
    "        \n",
    "\n",
    "    def compute_gradient_penalty(self, real_data, fake_data):\n",
    "        \"\"\"\n",
    "        Gradient penalty for WGAN-GP.\n",
    "        \"\"\"\n",
    "        alpha = torch.rand(real_data.size(0), 1, 1, 1, device=self.device)\n",
    "        alpha = alpha.expand(real_data.size())\n",
    "\n",
    "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "        interpolates = torch.autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "        disc_interpolates = self.discriminator(interpolates)\n",
    "        grad_outputs = torch.ones(disc_interpolates.size(), device=self.device)\n",
    "\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=disc_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=grad_outputs,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        return gradient_penalty\n",
    "\n",
    "    def r1_penalty(self, real_data):\n",
    "        \"\"\"\n",
    "        R1 penalty for real images (StyleGAN approach).\n",
    "        \"\"\"\n",
    "        real_data.requires_grad = True\n",
    "        real_pred = self.discriminator(real_data)\n",
    "        grad_real = torch.autograd.grad(\n",
    "            outputs=real_pred.sum(),\n",
    "            inputs=real_data,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        r1_reg = torch.mean(grad_real.pow(2).sum(dim=[i for i in range(1, grad_real.ndim)]))\n",
    "        return r1_reg\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        gc.collect()\n",
    "        # Save checkpoint every 50 epochs\n",
    "        if self.current_epoch % 50 == 0:\n",
    "            self.trainer.save_checkpoint(filepath=f\"./checkpoint_{self.hparams.type_model}_seed{self.hparams.seed_value}.ckpt\")\n",
    "\n",
    "    def diversity_loss(self, fake_images):\n",
    "        \"\"\"\n",
    "        A simple diversity measure: average pairwise L2 distances among samples.\n",
    "        Minimizing the negative encourages more variety.\n",
    "        \"\"\"\n",
    "        batch_size = fake_images.size(0)\n",
    "        fake_images_flat = fake_images.view(batch_size, -1)\n",
    "        distances = torch.pdist(fake_images_flat, p=2)\n",
    "        diversity = distances.mean()\n",
    "        return -diversity\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Manual training loop step that alternates between G and D updates \n",
    "        based on the chosen adversarial objective.\n",
    "        \"\"\"\n",
    "        true = batch  # [N, 3, H, W]\n",
    "        noise = torch.randn((true.shape[0], self.hparams.latent_dim), device=self.device)\n",
    "\n",
    "        optimizer_dis = self.optimizers()[1]\n",
    "        optimizer_gen = self.optimizers()[0]\n",
    "        optimizer_dis.zero_grad()\n",
    "        optimizer_gen.zero_grad()\n",
    "\n",
    "        # If multiscale mode, prepare real_list, fake_list and follow the logic\n",
    "        if self.hparams.use_multiscale:\n",
    "            real_list = tensor_to_multiscale(true, max_resolution=self.hparams.resolution, min_resolution=8)\n",
    "            fake_list = self.generator(noise)  # [8x8, ..., resolution]\n",
    "            if batch_idx % 8 == 0:\n",
    "                self.log_data(real_list[-1], fake_list[-1])\n",
    "            # Choose loss function\n",
    "            if self.hparams.type_model == \"KL-GAN\":\n",
    "                # Combine real+fake\n",
    "                combined_list = combine_real_fake_for_kl(real_list, fake_list)\n",
    "                kl = self.discriminator(combined_list)  # forward_kl\n",
    "                self.log('Fake_dist/Train', kl, prog_bar=True, on_epoch=True)\n",
    "\n",
    "                # Generator: backward with -KL\n",
    "                (-kl).backward()\n",
    "                for name, param in self.generator.named_parameters():\n",
    "                    if param.grad is not None:\n",
    "                        param.grad.data = -param.grad.data\n",
    "                optimizer_gen.step()\n",
    "                optimizer_dis.step()\n",
    "                return fake_list[-1].detach()  # return the largest level\n",
    "                \n",
    "            elif self.hparams.type_model == \"LS-GAN\":\n",
    "                return self.ls_gan_step_multiscale(optimizer_gen, optimizer_dis, noise, real_list, fake_list, batch_idx)\n",
    "            elif self.hparams.type_model == \"WGAN-GP\":\n",
    "                return self.wgan_gp_step_multiscale(optimizer_gen, optimizer_dis, noise, real_list, fake_list, batch_idx)\n",
    "            elif self.hparams.type_model == \"Hinge-GAN\":\n",
    "                return self.hinge_gan_step_multiscale(optimizer_gen, optimizer_dis, noise, real_list, fake_list, batch_idx)\n",
    "            elif self.hparams.type_model == \"R1-GAN\":\n",
    "                return self.r1_regularized_hinge_step_multiscale(optimizer_gen, optimizer_dis, noise, real_list, fake_list, batch_idx)\n",
    "\n",
    "        else:\n",
    "            # If NOT multiscale mode, use old logic:\n",
    "            if self.hparams.type_model == \"KL-GAN\":\n",
    "                fake = self.kl_gan_step(optimizer_gen, optimizer_dis, noise, true, batch_idx)\n",
    "            elif self.hparams.type_model == \"LS-GAN\":\n",
    "                fake = self.ls_gan_step(optimizer_gen, optimizer_dis, noise, true, batch_idx)\n",
    "            elif self.hparams.type_model == \"WGAN-GP\":\n",
    "                fake = self.wgan_gp_step(optimizer_gen, optimizer_dis, noise, true, batch_idx)\n",
    "            elif self.hparams.type_model == \"Hinge-GAN\":\n",
    "                fake = self.hinge_gan_step(optimizer_gen, optimizer_dis, noise, true, batch_idx)\n",
    "            elif self.hparams.type_model == \"R1-GAN\":\n",
    "                fake = self.r1_regularized_hinge_step(optimizer_gen, optimizer_dis, noise, true, batch_idx)\n",
    "\n",
    "            return fake\n",
    "\n",
    "    def log_data(self, true, fake):\n",
    "        with torch.no_grad():\n",
    "            mu_real, cov_real, mu_fake, cov_fake = get_features_RegNet(true, fake, eps=10)\n",
    "            kl_div = calculate_kl_divergence(mu_real, cov_real, mu_fake, cov_fake)\n",
    "            self.log('KL_divergence/Train', kl_div, prog_bar=True, on_epoch=True)\n",
    "\n",
    "            dv = self.diversity_loss(fake)\n",
    "            self.log('Diversity/Train', -dv, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    # Different adversarial objectives (original)\n",
    "    def ls_gan_step(self, optimizer_gen, optimizer_dis, noise, true, batch_idx):\n",
    "        # Generator step\n",
    "        with optimizer_gen.toggle_model():\n",
    "            fake = self.generator(noise)\n",
    "            if batch_idx % 8 == 0:\n",
    "                self.log_data(true, fake)\n",
    "            g_loss = self.discriminator(fake)\n",
    "            self.log('g_loss_ls_gan/Train', g_loss.mean(), prog_bar=True, on_epoch=True)\n",
    "            torch.mean(g_loss ** 2).backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "        # Discriminator step\n",
    "        fake = fake.detach()\n",
    "        with optimizer_dis.toggle_model():\n",
    "            true_loss = self.discriminator(true)\n",
    "            fake_loss = self.discriminator(fake)\n",
    "            self.log('true_loss_ls_gan/Train', true_loss.mean(), prog_bar=True, on_epoch=True)\n",
    "            self.log('fake_loss_ls_gan/Train', fake_loss.mean(), prog_bar=True, on_epoch=True)\n",
    "\n",
    "            true_loss = torch.mean((true_loss) ** 2)\n",
    "            fake_loss = torch.mean((fake_loss - 1) ** 2)\n",
    "            loss = (true_loss + fake_loss)\n",
    "            loss.backward()\n",
    "            optimizer_dis.step()\n",
    "\n",
    "        return fake\n",
    "\n",
    "    def kl_gan_step(self, optimizer_gen, optimizer_dis, noise, true, batch_idx):\n",
    "        fake = self.generator(noise)\n",
    "        if batch_idx % 8 == 0:\n",
    "            self.log_data(true, fake)\n",
    "        kl = self.discriminator(torch.cat([true, fake], dim=0))\n",
    "        self.log('Fake_dist/Train', kl, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        (-kl).backward()\n",
    "        for name, param in self.generator.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                param.grad.data = -param.grad.data\n",
    "\n",
    "        optimizer_gen.step()\n",
    "        optimizer_dis.step()\n",
    "        return fake.detach()\n",
    "\n",
    "    def wgan_gp_step(self, optimizer_gen, optimizer_dis, noise, true, batch_idx):\n",
    "        with optimizer_gen.toggle_model():\n",
    "            fake = self.generator(noise)\n",
    "            if batch_idx % 8 == 0:\n",
    "                self.log_data(true, fake)\n",
    "            gen_loss = -self.discriminator(fake).mean()\n",
    "            gen_loss.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "        fake = fake.detach()\n",
    "        with optimizer_dis.toggle_model():\n",
    "            real_pred = self.discriminator(true)\n",
    "            fake_pred = self.discriminator(fake)\n",
    "            gp = self.compute_gradient_penalty(true, fake)\n",
    "            dis_loss = (fake_pred.mean() - real_pred.mean()) + 10.0 * gp\n",
    "            dis_loss.backward()\n",
    "            optimizer_dis.step()\n",
    "\n",
    "        self.log('g_loss_wgan_gp/Train', gen_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('d_loss_wgan_gp/Train', dis_loss, prog_bar=True, on_epoch=True)\n",
    "        return fake\n",
    "\n",
    "    def hinge_gan_step(self, optimizer_gen, optimizer_dis, noise, true, batch_idx):\n",
    "        with optimizer_gen.toggle_model():\n",
    "            fake = self.generator(noise)\n",
    "            if batch_idx % 8 == 0:\n",
    "                self.log_data(true, fake)\n",
    "            gen_loss = -self.discriminator(fake).mean()\n",
    "            gen_loss.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "        fake = fake.detach()\n",
    "        with optimizer_dis.toggle_model():\n",
    "            real_pred = self.discriminator(true)\n",
    "            fake_pred = self.discriminator(fake)\n",
    "            d_loss_real = torch.mean(F.relu(1 - real_pred))\n",
    "            d_loss_fake = torch.mean(F.relu(1 + fake_pred))\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss.backward()\n",
    "            optimizer_dis.step()\n",
    "\n",
    "        self.log('g_loss_hinge/Train', gen_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('d_loss_hinge/Train', d_loss, prog_bar=True, on_epoch=True)\n",
    "        return fake\n",
    "\n",
    "    def r1_regularized_hinge_step(self, optimizer_gen, optimizer_dis, noise, true, batch_idx):\n",
    "        with optimizer_gen.toggle_model():\n",
    "            fake = self.generator(noise)\n",
    "            if batch_idx % 8 == 0:\n",
    "                self.log_data(true, fake)\n",
    "            gen_loss = -self.discriminator(fake).mean()\n",
    "            gen_loss.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "        fake = fake.detach()\n",
    "        with optimizer_dis.toggle_model():\n",
    "            real_pred = self.discriminator(true)\n",
    "            fake_pred = self.discriminator(fake)\n",
    "            d_loss_real = torch.mean(F.relu(1 - real_pred))\n",
    "            d_loss_fake = torch.mean(F.relu(1 + fake_pred))\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            r1 = self.r1_penalty(true) * 10.0\n",
    "            total_loss = d_loss + r1\n",
    "            total_loss.backward()\n",
    "            optimizer_dis.step()\n",
    "\n",
    "        self.log('g_loss_r1_hinge/Train', gen_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('d_loss_r1_hinge/Train', d_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('r1_penalty/Train', r1, prog_bar=True, on_epoch=True)\n",
    "        return fake\n",
    "\n",
    "    # New multiscale methods (following similar logic at the \"last\" level)\n",
    "    def ls_gan_step_multiscale(self, optimizer_gen, optimizer_dis, noise, real_list, fake_list, batch_idx):\n",
    "        with optimizer_gen.toggle_model():\n",
    "            fake_high = fake_list[-1]\n",
    "            true_high = real_list[-1]\n",
    "            if batch_idx % 8 == 0:\n",
    "                self.log_data(true_high, fake_high)\n",
    "            g_loss = self.discriminator(fake_list)\n",
    "            torch.mean(g_loss ** 2).backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "        fake_high = fake_high.detach()\n",
    "        with optimizer_dis.toggle_model():\n",
    "            true_loss = self.discriminator(real_list)\n",
    "            fake_loss = self.discriminator(fake_list)\n",
    "            true_loss = torch.mean((true_loss) ** 2)\n",
    "            fake_loss = torch.mean((fake_loss - 1) ** 2)\n",
    "            loss = (true_loss + fake_loss)\n",
    "            loss.backward()\n",
    "            optimizer_dis.step()\n",
    "\n",
    "        return fake_high\n",
    "\n",
    "    def wgan_gp_step_multiscale(self, optimizer_gen, optimizer_dis, noise, real_list, fake_list, batch_idx):\n",
    "        with optimizer_gen.toggle_model():\n",
    "            fake_high = fake_list[-1]\n",
    "            true_high = real_list[-1]\n",
    "            if batch_idx % 8 == 0:\n",
    "                self.log_data(true_high, fake_high)\n",
    "            gen_loss = -self.discriminator(fake_list).mean()\n",
    "            gen_loss.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "        fake_high = fake_high.detach()\n",
    "        with optimizer_dis.toggle_model():\n",
    "            real_pred = self.discriminator(real_list)\n",
    "            fake_pred = self.discriminator(fake_list)\n",
    "            # GP at the last level:\n",
    "            gp = self.compute_gradient_penalty(true_high, fake_high)\n",
    "            dis_loss = (fake_pred.mean() - real_pred.mean()) + 10.0 * gp\n",
    "            dis_loss.backward()\n",
    "            optimizer_dis.step()\n",
    "\n",
    "        self.log('g_loss_wgan_gp/Train', gen_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('d_loss_wgan_gp/Train', dis_loss, prog_bar=True, on_epoch=True)\n",
    "        return fake_high\n",
    "\n",
    "    def hinge_gan_step_multiscale(self, optimizer_gen, optimizer_dis, noise, real_list, fake_list, batch_idx):\n",
    "        with optimizer_gen.toggle_model():\n",
    "            fake_high = fake_list[-1]\n",
    "            true_high = real_list[-1]\n",
    "            if batch_idx % 8 == 0:\n",
    "                self.log_data(true_high, fake_high)\n",
    "            gen_loss = -self.discriminator(fake_list).mean()\n",
    "            gen_loss.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "        fake_high = fake_high.detach()\n",
    "        with optimizer_dis.toggle_model():\n",
    "            real_pred = self.discriminator(real_list)\n",
    "            fake_pred = self.discriminator(fake_list)\n",
    "            d_loss_real = torch.mean(F.relu(1 - real_pred))\n",
    "            d_loss_fake = torch.mean(F.relu(1 + fake_pred))\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            d_loss.backward()\n",
    "            optimizer_dis.step()\n",
    "\n",
    "        self.log('g_loss_hinge/Train', gen_loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('d_loss_hinge/Train', d_loss, prog_bar=True, on_epoch=True)\n",
    "        return fake_high\n",
    "\n",
    "    def r1_regularized_hinge_step_multiscale(self, optimizer_gen, optimizer_dis, noise, real_list, fake_list, batch_idx):\n",
    "        with optimizer_gen.toggle_model():\n",
    "            fake_high = fake_list[-1]\n",
    "            true_high = real_list[-1]\n",
    "            if batch_idx % 8 == 0:\n",
    "                self.log_data(true_high, fake_high)\n",
    "            gen_loss = -self.discriminator(fake_list).mean()\n",
    "            gen_loss.backward()\n",
    "            optimizer_gen.step()\n",
    "\n",
    "        fake_high = fake_high.detach()\n",
    "        with optimizer_dis.toggle_model():\n",
    "            real_pred = self.discriminator(real_list)\n",
    "            fake_pred = self.discriminator(fake_list)\n",
    "            d_loss_real = torch.mean(F.relu(1 - real_pred))\n",
    "            d_loss_fake = torch.mean(F.relu(1 + fake_pred))\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            r1 = self.r1_penalty(true_high) * 10.0\n",
    "            total_loss = d_loss + r1\n",
    "            total_loss.backward()\n",
    "            optimizer_dis.step()\n",
    "\n",
    "        return fake_high\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if batch_idx == 0:  # Initialize accumulators with first batch\n",
    "            self.val_features_real = []\n",
    "            self.val_features_fake = []\n",
    "            \n",
    "            # Log real and fake images as before\n",
    "            real = batch\n",
    "            resize_transform = transforms.Resize((299, 299), antialias=True)\n",
    "            real_resized = resize_transform(real)\n",
    "            \n",
    "            if self.current_epoch == 0:\n",
    "                self.logger.experiment.log({\n",
    "                    \"Real\": [wandb.Image(\n",
    "                        real_resized[0].permute(1,2,0).detach().float().cpu().numpy(),\n",
    "                        caption=\" \"\n",
    "                    )]\n",
    "                })\n",
    "                self.noise_fixed = torch.randn((10000, self.hparams.latent_dim), device=self.device)\n",
    "\n",
    "        # Collect features for FID in batches\n",
    "        if batch_idx * batch.shape[0] < 10000:\n",
    "            real = batch\n",
    "            resize_transform = transforms.Resize((299, 299), antialias=True)\n",
    "            real_resized = resize_transform(real)\n",
    "            \n",
    "            # Generate fakes for current batch\n",
    "            current_noise = self.noise_fixed[batch_idx * batch.shape[0]:(batch_idx + 1) * batch.shape[0]]\n",
    "            if self.hparams.use_multiscale:\n",
    "                fake_list = self.generator(current_noise)\n",
    "                fake = fake_list[-1]  # take the last level\n",
    "            else:\n",
    "                fake = self.generator(current_noise)\n",
    "            fake_resized = resize_transform(fake)\n",
    "\n",
    "            # Get features through inception\n",
    "            with torch.no_grad():\n",
    "                real_features = inception_model(real_resized)\n",
    "                fake_features = inception_model(fake_resized)\n",
    "                \n",
    "                self.val_features_real.append(real_features.cpu())\n",
    "                self.val_features_fake.append(fake_features.cpu())\n",
    "\n",
    "        # Calculate FID in the last batch\n",
    "        if (batch_idx + 1) * batch.shape[0] >= 10000 and self.val_features_real != None:\n",
    "            # Collect all features\n",
    "            all_real_features = torch.cat(self.val_features_real, dim=0)[:10000]\n",
    "            all_fake_features = torch.cat(self.val_features_fake, dim=0)[:10000]\n",
    "            \n",
    "            # Calculate statistics\n",
    "            mu_real = all_real_features.mean(0)\n",
    "            mu_fake = all_fake_features.mean(0)\n",
    "            \n",
    "            cov_real = torch.cov(all_real_features.permute(1,0))\n",
    "            cov_fake = torch.cov(all_fake_features.permute(1,0))\n",
    "            \n",
    "            # Add eps for numerical stability\n",
    "            eps = 1e-8\n",
    "            cov_real += eps * torch.eye(cov_real.size(0)).to(cov_real.device)\n",
    "            cov_fake += eps * torch.eye(cov_fake.size(0)).to(cov_fake.device)\n",
    "            \n",
    "            # Calculate FID\n",
    "            fid_value = calculate_fid(mu_real, cov_real, mu_fake, cov_fake)\n",
    "            self.log('FID/Validation', fid_value, prog_bar=True, on_epoch=True)\n",
    "            \n",
    "            # Clear memory\n",
    "            del self.val_features_real\n",
    "            del self.val_features_fake\n",
    "            torch.cuda.empty_cache()\n",
    "            self.val_features_real = None\n",
    "            self.val_features_fake = None\n",
    "            \n",
    "            # Log grid as before\n",
    "            images = []\n",
    "            for i in range(10):\n",
    "                for _ in range(5):\n",
    "                    noise = torch.randn(1, self.hparams.latent_dim, device=self.device)\n",
    "                    if self.hparams.use_multiscale:\n",
    "                        generated_list = self.generator(noise)\n",
    "                        image = generated_list[-1]\n",
    "                    else:\n",
    "                        image = self.generator(noise)\n",
    "                    images.append(image)\n",
    "\n",
    "            images_resized = [F.interpolate(img, size=(64, 64))[0] for img in images]\n",
    "            images_grid = torchvision.utils.make_grid(images_resized, nrow=5)\n",
    "            self.logger.experiment.log({\n",
    "                \"Validation_panel\": [wandb.Image(\n",
    "                    images_grid.permute(1,2,0).detach().float().cpu().numpy(),\n",
    "                    caption=\"All\"\n",
    "                )]\n",
    "            })\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.learning_rate\n",
    "        optimizer_gen = torch.optim.AdamW(\n",
    "            self.generator.parameters(),\n",
    "            lr=lr\n",
    "        )\n",
    "        optimizer_disc = torch.optim.AdamW(\n",
    "            self.discriminator.parameters(),\n",
    "            lr=lr * 0.5 if self.hparams.use_minibatch and self.hparams.type_model != \"R1-GAN\" and self.hparams.type_model != \"LS-GAN\" else lr\n",
    "        )\n",
    "        scheduler_gen = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer_gen,\n",
    "            start_factor=1.0,\n",
    "            end_factor=0.01,\n",
    "            total_iters=300000\n",
    "        )\n",
    "        scheduler_disc = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer_disc,\n",
    "            start_factor=1.0,\n",
    "            end_factor=0.01,\n",
    "            total_iters=300000\n",
    "        )\n",
    "        return [\n",
    "            {\n",
    "                \"optimizer\": optimizer_gen,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler_gen,\n",
    "                    \"interval\": \"step\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"optimizer\": optimizer_disc,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler_disc,\n",
    "                    \"interval\": \"step\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "\n",
    "# Additional functions for multiscale (needed to transform real into a list, etc.)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def tensor_to_multiscale(real, max_resolution=32, min_resolution=8):\n",
    "    \"\"\"\n",
    "    Transform tensor [N, 3, max_resolution, max_resolution] into a list\n",
    "    [4x4, 8x8, 16x16, 32x32].\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    current_res = min_resolution\n",
    "    while current_res <= max_resolution:\n",
    "        scaled = F.interpolate(\n",
    "            real,\n",
    "            size=(current_res, current_res),\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "        images.append(scaled)\n",
    "        current_res *= 2\n",
    "    return images\n",
    "\n",
    "def combine_real_fake_for_kl(real_list, fake_list):\n",
    "    \"\"\"\n",
    "    At each level, concatenate along batch dimension: [N + N, 3, H, W].\n",
    "    \"\"\"\n",
    "    combined = []\n",
    "    for r, f in zip(real_list, fake_list):\n",
    "        combined.append(torch.cat([r, f], dim=0))\n",
    "    return combined\n",
    "\n",
    "\n",
    "# Running multiple seeds for each method\n",
    "if __name__ == \"__main__\":\n",
    "    wandb.login(key=\"\") #key=\"...\"\n",
    "\n",
    "    # Common config\n",
    "    Project_name = \"KL-GAN CelebA Experiment\"\n",
    "    methods = [\"KL-GAN\", \"R1-GAN\", \"LS-GAN\", \"WGAN-GP\", \"Hinge-GAN\"]\n",
    "    seeds = [1, 2, 3, 4, 5]\n",
    "\n",
    "    for method in methods:\n",
    "        for seed in seeds:\n",
    "            for use_minibatch in [True, False]:\n",
    "                for use_multiscale in [False]:\n",
    "                    minibatch_suffix = \"with_minibatch\" if use_minibatch else \"no_minibatch\"\n",
    "                    scale_suffix = \"multiscale\" if use_multiscale else \"single_scale\"\n",
    "                    run_name = f\"{method}_{minibatch_suffix}_{scale_suffix}\"\n",
    "                    wandb_logger = WandbLogger(\n",
    "                        name=run_name,\n",
    "                        project=Project_name,\n",
    "                        save_dir=\"./wandb_logs\",\n",
    "                        version=None,\n",
    "                        reinit=True\n",
    "                    )\n",
    "\n",
    "                    CustomProgressBar = RichProgressBar(\n",
    "                        refresh_rate=20,\n",
    "                        theme=RichProgressBarTheme(\n",
    "                            description=\"green_yellow\",\n",
    "                            progress_bar=\"green1\",\n",
    "                            progress_bar_finished=\"green1\",\n",
    "                            progress_bar_pulse=\"#6206E0\",\n",
    "                            batch_progress=\"green_yellow\",\n",
    "                            time=\"grey82\",\n",
    "                            processing_speed=\"grey82\",\n",
    "                            metrics=\"grey82\",\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    trainer = pl.Trainer(\n",
    "                        accelerator=\"gpu\",\n",
    "                        devices=\"auto\",\n",
    "                        precision=\"bf16-mixed\",\n",
    "                        log_every_n_steps=40,\n",
    "                        callbacks=[CustomProgressBar],\n",
    "                        logger=[wandb_logger],\n",
    "                        max_epochs=300,\n",
    "                        limit_train_batches=1.0,\n",
    "                        check_val_every_n_epoch=50\n",
    "                    )\n",
    "\n",
    "                    model = GAN_Training(\n",
    "                        learning_rate=0.00008,\n",
    "                        batch_size=1024,\n",
    "                        seed_value=seed,\n",
    "                        type_model=method,\n",
    "                        latent_dim=128,\n",
    "                        dim=128,\n",
    "                        use_minibatch=use_minibatch,\n",
    "                        use_multiscale=use_multiscale,\n",
    "                    )\n",
    "\n",
    "                    datamodule = DataModule(\n",
    "                        batch_size=model.hparams.batch_size,\n",
    "                        val_batch_size=1024,\n",
    "                        data_dir=\"./img_align_celeba/img_align_celeba\"\n",
    "                    )\n",
    "\n",
    "                    trainer.fit(model, datamodule)\n",
    "                    wandb_logger.experiment.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48d49c-13ce-46b1-980d-e08eff898923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
